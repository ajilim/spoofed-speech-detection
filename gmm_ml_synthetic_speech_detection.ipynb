{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spoofed Speech Detection via Maximum Likelihood Estimation of Gaussian Mixture Models\n",
    "The goal of synthetic speech detection is to determine whether a speech segment $S$ is natural or synthetic/converted speeach.\n",
    "\n",
    "This notebook implements a Gaussian mixture model maximum likelihood (GMM-ML) classifier for synthetic (spoofed) speech detection. This approach uses regular mel frequency cepstral coefficients (MFCC) features and gives the best performance on the [ASVspoof 2015 dataset](https://www.idiap.ch/dataset/avspoof) among the standard classifiers (GMM-SV, GMM-UBM, ...). For more background information see: *HanilÃ§i, Cemal, Tomi Kinnunen, Md Sahidullah, and Aleksandr Sizov. \"Classifiers for synthetic speech detection: a comparison.\" In INTERSPEECH 2015*. The scripts use the Python package [Bob.Bio.SPEAR 2.04](https://pypi.python.org/pypi/bob.bio.spear/2.0.4) for speaker recogntion.\n",
    "\n",
    "This work is part of the [\"DDoS Resilient Emergency Dispatch Center\"](https://www.dhs.gov/science-and-technology/news/2015/09/04/dhs-st-awards-university-houston-26m-cyber-security-research) project at the University of Houston, funded by the Department of Homeland Security (DHS).\n",
    "\n",
    "\n",
    "April 19, 2015\n",
    "\n",
    "Lorenzo Rossi\n",
    "\n",
    "(lorenzo **[dot]** rossi **[at]** gmail **[dot]** com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bob.bio.spear import preprocessor, extractor\n",
    "from bob.bio.gmm import algorithm\n",
    "from bob.io.base import HDF5File\n",
    "from bob.learn import em\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score\n",
    "\n",
    "WAV_FOLDER = 'Wav/' #'ASV2015dataset/wav/' # Path to folder containing speakers .wav subfolders\n",
    "LABEL_FOLDER = 'CM_protocol/' #'ASV2015dataset/CM_protocol/' # Path to ground truth csv files\n",
    "\n",
    "EXT = '.wav'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Ground Truth\n",
    "Load the dataframes (tables) with the labels for the training, development and evaluation (hold out) sets. Each subfolder corresponds to a different speaker. For example, T1 and D4 indicate the subfolders associated to the utterances and spoofed segments of speakers T1 and D4, respectively in training and development sets. Note that number of evaluation samples >> number of development samples >> testing samples.\n",
    "\n",
    "You can either select the speakers in each set one by one, *e.g.*:\n",
    "```\n",
    "train_subfls = ['T1', 'T2']\n",
    "``` \n",
    "will only load segments from speakers T1 and T2 for training,\n",
    "\n",
    "or use all the available speakers in a certain subset by leaving the list empty, *e.g.*:\n",
    "```\n",
    "devel_subfls = [] \n",
    "```\n",
    "will load all the available Dx speaker segments for the development stage. If you are running this notebook for the first time, you may want to start only with 2 or so speakers per set for sake of quick testing. All the scripts may take several hours to run on the full size datsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training samples: 655\n",
      "development samples: 1525\n",
      "evaluation samples: 4185\n"
     ]
    }
   ],
   "source": [
    "train_subfls = ['T1']#, 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'T13']  #T13 used instead of T10 for gender balance\n",
    "devel_subfls = ['D1']#, 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10']\n",
    "evalu_subfls = ['E1']#, 'E2', 'E3', 'E4', 'E5', 'E6','E7',  'E8', 'E9', 'E10']\n",
    "train = pd.read_csv(LABEL_FOLDER + 'cm_train.trn', sep=' ', header=None, names=['folder','file','method','source'])\n",
    "if len(train_subfls): train = train[train.folder.isin(train_subfls)]\n",
    "train.sort_values(['folder', 'file'], inplace=True)\n",
    "devel = pd.read_csv(LABEL_FOLDER + 'cm_develop.ndx', sep=' ', header=None, names=['folder','file','method','source'])\n",
    "if len(devel_subfls): devel = devel[devel.folder.isin(devel_subfls)]\n",
    "devel.sort_values(['folder', 'file'], inplace=True)\n",
    "evalu = pd.read_csv(LABEL_FOLDER +'cm_evaluation.ndx', sep=' ', header=None, names=['folder','file','method','source'])\n",
    "if len(evalu_subfls): evalu = evalu[evalu.folder.isin(evalu_subfls)]\n",
    "\n",
    "evalu.sort_values(['folder', 'file'], inplace=True)\n",
    "\n",
    "label_2_class = {'human':1, 'spoof':0}\n",
    "\n",
    "print('training samples:',len(train))\n",
    "print('development samples:',len(devel))\n",
    "print('evaluation samples:',len(evalu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Preprocessing and MFCC Extraction\n",
    "Silence removal and MFCC feature extraction for training segments. More details about the bob.bio.spear involved libraries at:\n",
    "https://www.idiap.ch/software/bob/docs/latest/bioidiap/bob.bio.spear/master/implemented.html\n",
    "\n",
    "You can also skip this stage and load a set of feaures (see **Loading features** cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_ceps = 60 # number of ceptral coefficients (implicit in extractor)\n",
    "silence_removal_ratio = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for training stage.\n",
      "T1, 655 files processed in 1.8766250499999992 minutes.\n"
     ]
    }
   ],
   "source": [
    "subfolders = train_subfls\n",
    "ground_truth = train\n",
    "\n",
    "# initialize feature matrix\n",
    "features = []\n",
    "y = np.zeros((len(ground_truth),))\n",
    "print(\"Extracting features for training stage.\")\n",
    "\n",
    "vad = preprocessor.Energy_Thr(ratio_threshold=silence_removal_ratio)\n",
    "cepstrum = extractor.Cepstral()\n",
    "\n",
    "k = 0\n",
    "start_time = time.clock()\n",
    "\n",
    "for folder in subfolders[0:n_subfls]:\n",
    "    print(folder, end=\", \")\n",
    "    folder = \"\".join(('Wav/',folder,'/'))\n",
    "    f_list = os.listdir(folder)\n",
    "    for f_name in f_list:\n",
    "        # ground truth\n",
    "        try: \n",
    "            label = ground_truth[ground_truth.file==f_name[:-len(EXT)]].source.values[0]\n",
    "        except IndexError:\n",
    "            continue\n",
    "        y[k] = label_2_class[label]\n",
    "        # silence removal\n",
    "        x = vad.read_original_data(folder+f_name)\n",
    "        vad_data = vad(x)\n",
    "        if not vad_data[2].max():\n",
    "            vad = preprocessor.Energy_Thr(ratio_threshold=silence_removal_ratio*.8)\n",
    "            vad_data = vad(x)\n",
    "            vad = preprocessor.Energy_Thr(ratio_threshold=silence_removal_ratio)\n",
    "        # MFCC extraction \n",
    "        mfcc = cepstrum(vad_data)\n",
    "        features.append(mfcc)\n",
    "        k += 1\n",
    "\n",
    "Xf = np.array(features)\n",
    "print(k,\"files processed in\",(time.clock()-start_time)/60,\"minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('X.npy',Xf)\n",
    "np.save('y.npy',y)\n",
    "print('Feature and label matrices saved to disk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load already extracter features to skip the preprocessing-extraction stage\n",
    "Xf = np.load('train_features_10.npy')\n",
    "y = np.load('y_10.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM - ML Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM Training\n",
    "Train the GMMs for natural and synthetic speach. For documentation on bob.bio k-means and GMM machines see:\n",
    "https://pythonhosted.org/bob.learn.em/guide.html\n",
    "\n",
    "You can also skip the training stage and load an already trained GMM model (see cell **Loading GMM Model**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters of the GMM machines\n",
    "n_gaussians = 128 # number of Gaussians\n",
    "max_iterats = 25 # maximum number of iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM for natural speech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in: 1.7726312666666666 minutes\n",
      "<bob.learn.em.GMMMachine object at 0x7fc500be12d0>\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train k-means machine: the means will initialize EM algorithm for GMM machine\n",
    "start_time = time.clock()\n",
    "kmeans_nat = em.KMeansMachine(n_gaussians,n_ceps)\n",
    "kmeansTrainer = em.KMeansTrainer()\n",
    "em.train(kmeansTrainer, kmeans_nat, np.vstack(Xf[y==1]), max_iterations = max_iterats, convergence_threshold = 1e-5)\n",
    "#kmeans_nat.means\n",
    "\n",
    "# initialize and train GMM machine\n",
    "gmm_nat = em.GMMMachine(n_gaussians,n_ceps)\n",
    "trainer = em.ML_GMMTrainer(True, True, True)\n",
    "gmm_nat.means = kmeans_nat.means\n",
    "em.train(trainer, gmm_nat, np.vstack(Xf[y==1]), max_iterations = max_iterats, convergence_threshold = 1e-5)\n",
    "#gmm_nat.save(HDF5File('gmm_nat.hdf5', 'w'))\n",
    "print(\"Done in:\", (time.clock() - start_time)/60, \"minutes\")\n",
    "print(gmm_nat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM for synthetic speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in: 6.424915316666667 minutes\n",
      "<bob.learn.em.GMMMachine object at 0x7fc500be1330>\n"
     ]
    }
   ],
   "source": [
    "# initialize and train k-means machine: the means will initialize EM algorithm for GMM machine\n",
    "start_time = time.clock()\n",
    "kmeans_synt = em.KMeansMachine(n_gaussians,n_ceps)\n",
    "kmeansTrainer = em.KMeansTrainer()\n",
    "em.train(kmeansTrainer, kmeans_synt, np.vstack(Xf[y==0]), max_iterations = max_iterats, convergence_threshold = 1e-5)\n",
    "\n",
    "# initialize and train GMM machine\n",
    "gmm_synt = em.GMMMachine(n_gaussians,n_ceps)\n",
    "trainer = em.ML_GMMTrainer(True, True, True)\n",
    "gmm_synt.means = kmeans_synt.means\n",
    "em.train(trainer, gmm_synt, np.vstack(Xf[y==0]), max_iterations = max_iterats, convergence_threshold = 1e-5)\n",
    "print(\"Done in:\", (time.clock() - start_time)/60, \"minutes\")\n",
    "#gmm_synt.save(HDF5File('gmm_synt.hdf5', 'w'))\n",
    "print(gmm_synt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading GMM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gmm_nat = em.GMMMachine()\n",
    "gmm_nat.load(HDF5File('gmm_nat.hdf5', 'r'))\n",
    "gmm_synt = em.GMMMachine()\n",
    "gmm_synt.load(HDF5File('gmm_synt.hdf5','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('p_gmm_ml_eval_10.npy',llr_score)\n",
    "np.save('z_gmm_ml_eval_est_10.npy',z_gmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## GMM-ML Scoring\n",
    "Extract the features for the testing data, compute the likelihood ratio test and  compute ROC AUC and estimated EER scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devel\n",
      "D1,0.950263157895\n",
      "1525 files processed in 5.7873589999999995 minutes.\n",
      "ROC AUC score: 0.950263157895\n",
      "False negative rate %: 2.94736842105\n",
      "False positive rate %: 7.0\n",
      "EER %: <= 4.97368421053\n"
     ]
    }
   ],
   "source": [
    "status = 'devel' # 'devel'(= test) OR 'evalu'(= hold out)\n",
    "start_time = time.clock()\n",
    "\n",
    "if status == 'devel':\n",
    "    subfolders = devel_subfls\n",
    "    ground_truth = devel\n",
    "elif status == 'evalu':\n",
    "    subfolders = evalu_subfls\n",
    "    ground_truth = evalu\n",
    "n_subfls = len(subfolders)\n",
    "# initialize score and class arrays\n",
    "llr_gmm_score = np.zeros(len(ground_truth),)\n",
    "z_gmm = np.zeros(len(ground_truth),)\n",
    "print(status)\n",
    "\n",
    "vad = preprocessor.Energy_Thr(ratio_threshold=.1)\n",
    "cepstrum = extractor.Cepstral()\n",
    "\n",
    "k = 0\n",
    "thr = .5\n",
    "speaker_list = ground_truth.folder.unique()\n",
    "\n",
    "for speaker_id in speaker_list:\n",
    "    #speaker = ground_truth[ground_truth.folder==speaker_id]\n",
    "    f_list = list(ground_truth[ground_truth.folder==speaker_id].file)\n",
    "    folder = \"\".join(['Wav/',speaker_id,'/'])\n",
    "    print(speaker_id, end=',')\n",
    "\n",
    "    for f in f_list:\n",
    "        f_name = \"\".join([folder,f,'.wav'])\n",
    "        x = vad.read_original_data(f_name)\n",
    "        # voice activity detection\n",
    "        vad_data = vad(x)\n",
    "        if not vad_data[2].max():\n",
    "            vad = preprocessor.Energy_Thr(ratio_threshold=.08)\n",
    "            vad_data = vad(x)\n",
    "            vad = preprocessor.Energy_Thr(ratio_threshold=.1)\n",
    "        # MFCC extraction \n",
    "        mfcc = cepstrum(vad_data)\n",
    "        # Log likelihood ratio computation\n",
    "        llr_gmm_score[k] = gmm_nat(mfcc)-gmm_synt(mfcc)\n",
    "        z_gmm[k] = int(llr_gmm_score[k]>0)\n",
    "        k += 1\n",
    "\n",
    "ground_truth['z'] = ground_truth.source.map(lambda x: int(x=='human'))\n",
    "ground_truth['z_gmm'] = z_gmm\n",
    "ground_truth['score_gmm'] = llr_gmm_score\n",
    "print(roc_auc_score(ground_truth.z, ground_truth.z_gmm))\n",
    "print(k,\"files processed in\",(time.clock()-start_time)/60,\"minutes.\")\n",
    "\n",
    "# Performance evaluation\n",
    "humans = z_gmm[z_dvl==0]\n",
    "spoofed = z_gmm[z_dvl==1]\n",
    "fnr = 100*(1-(humans<thr).sum()/len(humans))\n",
    "fpr = 100*(1-(spoofed>=thr).sum()/len(spoofed))\n",
    "print(\"ROC AUC score:\", roc_auc_score(z_dvl,z_gmm))\n",
    "print(\"False negative rate %:\", fnr)\n",
    "print(\"False positive rate %:\", fpr)\n",
    "print(\"EER %: <=\", (fnr+fpr)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EER computation\n",
    "\n",
    "Adjust the threshold $thr$ to reduce $FNR-FPR$ for a more accurate estimate of the $EER$.\n",
    "\n",
    "The Equal Error Rate ($EER$) is the value where the false negative rate ($FNR$) equals the false positive rate ($FPR$). It's an error metric commonly used to characterize biometric systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False negative vs positive rates %: 3.36842105263 3.0\n",
      "FNR - FPR %: 0.368421052632\n",
      "EER ~ 3.18421052632 %\n"
     ]
    }
   ],
   "source": [
    "thr = -.115\n",
    "pz = llr_gmm_score\n",
    "spoofed = pz[np.array(ground_truth.z)==1]\n",
    "humans = pz[np.array(ground_truth.z)==0]\n",
    "fnr = 100*(humans>thr).sum()/len(humans)\n",
    "fpr = 100*(spoofed<=thr).sum()/len(spoofed)\n",
    "print(\"False negative vs positive rates %:\", fnr, fpr)\n",
    "print(\"FNR - FPR %:\", fnr-fpr)\n",
    "if np.abs(fnr-fpr) <.25:\n",
    "    print(\"EER =\", (fnr+fpr)/2,\"%\")\n",
    "else:\n",
    "    print(\"EER ~\", (fnr+fpr)/2,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
